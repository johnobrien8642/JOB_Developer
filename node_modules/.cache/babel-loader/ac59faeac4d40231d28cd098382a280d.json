{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.ReadStreamTokenizer = void 0;\n\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\n\nconst peek_readable_1 = require(\"peek-readable\"); // import * as _debug from 'debug';\n// const debug = _debug('strtok3:ReadStreamTokenizer');\n\n\nconst maxBufferSize = 256000;\n\nclass ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\n  constructor(stream, fileInfo) {\n    super(fileInfo);\n    this.streamReader = new peek_readable_1.StreamReader(stream);\n  }\n  /**\n   * Get file information, an HTTP-client may implement this doing a HEAD request\n   * @return Promise with file information\n   */\n\n\n  async getFileInfo() {\n    return this.fileInfo;\n  }\n  /**\n   * Read buffer from tokenizer\n   * @param buffer - Target buffer to fill with data read from the tokenizer-stream\n   * @param options - Read behaviour options\n   * @returns Promise with number of bytes read\n   */\n\n\n  async readBuffer(buffer, options) {\n    // const _offset = position ? position : this.position;\n    // debug(`readBuffer ${_offset}...${_offset + length - 1}`);\n    let offset = 0;\n    let length = buffer.length;\n\n    if (options) {\n      if (Number.isInteger(options.length)) {\n        length = options.length;\n      } else {\n        length -= options.offset || 0;\n      }\n\n      if (options.position) {\n        const skipBytes = options.position - this.position;\n\n        if (skipBytes > 0) {\n          await this.ignore(skipBytes);\n          return this.readBuffer(buffer, options);\n        } else if (skipBytes < 0) {\n          throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n      }\n\n      if (options.offset) {\n        offset = options.offset;\n      }\n    }\n\n    if (length === 0) {\n      return 0;\n    }\n\n    const bytesRead = await this.streamReader.read(buffer, offset, length);\n    this.position += bytesRead;\n\n    if ((!options || !options.mayBeLess) && bytesRead < length) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return bytesRead;\n  }\n  /**\n   * Peek (read ahead) buffer from tokenizer\n   * @param buffer - Target buffer to write the data read to\n   * @param options - Read behaviour options\n   * @returns Promise with number of bytes peeked\n   */\n\n\n  async peekBuffer(buffer, options) {\n    // const _offset = position ? position : this.position;\n    // debug(`peek ${_offset}...${_offset + length - 1}`);\n    let offset = 0;\n    let bytesRead;\n    let length = buffer.length;\n\n    if (options) {\n      if (options.offset) {\n        offset = options.offset;\n      }\n\n      if (Number.isInteger(options.length)) {\n        length = options.length;\n      } else {\n        length -= options.offset || 0;\n      }\n\n      if (options.position) {\n        const skipBytes = options.position - this.position;\n\n        if (skipBytes > 0) {\n          const skipBuffer = Buffer.alloc(length + skipBytes);\n          bytesRead = await this.peekBuffer(skipBuffer, {\n            mayBeLess: options.mayBeLess\n          });\n          skipBuffer.copy(buffer, offset, skipBytes);\n          return bytesRead - skipBytes;\n        } else if (skipBytes < 0) {\n          throw new Error('Cannot peek from a negative offset in a stream');\n        }\n      }\n    }\n\n    try {\n      bytesRead = await this.streamReader.peek(buffer, offset, length);\n    } catch (err) {\n      if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {\n        return 0;\n      }\n\n      throw err;\n    }\n\n    if ((!options || !options.mayBeLess) && bytesRead < length) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return bytesRead;\n  }\n\n  async ignore(length) {\n    // debug(`ignore ${this.position}...${this.position + length - 1}`);\n    const bufSize = Math.min(maxBufferSize, length);\n    const buf = Buffer.alloc(bufSize);\n    let totBytesRead = 0;\n\n    while (totBytesRead < length) {\n      const remaining = length - totBytesRead;\n      const bytesRead = await this.readBuffer(buf, {\n        length: Math.min(bufSize, remaining)\n      });\n\n      if (bytesRead < 0) {\n        return bytesRead;\n      }\n\n      totBytesRead += bytesRead;\n    }\n\n    return totBytesRead;\n  }\n\n}\n\nexports.ReadStreamTokenizer = ReadStreamTokenizer;","map":{"version":3,"sources":["/Users/johnobrien/Desktop/Rumblr_PROD/client/node_modules/strtok3/lib/ReadStreamTokenizer.js"],"names":["Object","defineProperty","exports","value","ReadStreamTokenizer","AbstractTokenizer_1","require","peek_readable_1","maxBufferSize","AbstractTokenizer","constructor","stream","fileInfo","streamReader","StreamReader","getFileInfo","readBuffer","buffer","options","offset","length","Number","isInteger","position","skipBytes","ignore","Error","bytesRead","read","mayBeLess","EndOfStreamError","peekBuffer","skipBuffer","Buffer","alloc","copy","peek","err","bufSize","Math","min","buf","totBytesRead","remaining"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,mBAAR,GAA8B,KAAK,CAAnC;;AACA,MAAMC,mBAAmB,GAAGC,OAAO,CAAC,qBAAD,CAAnC;;AACA,MAAMC,eAAe,GAAGD,OAAO,CAAC,eAAD,CAA/B,C,CACA;AACA;;;AACA,MAAME,aAAa,GAAG,MAAtB;;AACA,MAAMJ,mBAAN,SAAkCC,mBAAmB,CAACI,iBAAtD,CAAwE;AACpEC,EAAAA,WAAW,CAACC,MAAD,EAASC,QAAT,EAAmB;AAC1B,UAAMA,QAAN;AACA,SAAKC,YAAL,GAAoB,IAAIN,eAAe,CAACO,YAApB,CAAiCH,MAAjC,CAApB;AACH;AACD;AACJ;AACA;AACA;;;AACqB,QAAXI,WAAW,GAAG;AAChB,WAAO,KAAKH,QAAZ;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVI,UAAU,CAACC,MAAD,EAASC,OAAT,EAAkB;AAC9B;AACA;AACA,QAAIC,MAAM,GAAG,CAAb;AACA,QAAIC,MAAM,GAAGH,MAAM,CAACG,MAApB;;AACA,QAAIF,OAAJ,EAAa;AACT,UAAIG,MAAM,CAACC,SAAP,CAAiBJ,OAAO,CAACE,MAAzB,CAAJ,EAAsC;AAClCA,QAAAA,MAAM,GAAGF,OAAO,CAACE,MAAjB;AACH,OAFD,MAGK;AACDA,QAAAA,MAAM,IAAIF,OAAO,CAACC,MAAR,IAAkB,CAA5B;AACH;;AACD,UAAID,OAAO,CAACK,QAAZ,EAAsB;AAClB,cAAMC,SAAS,GAAGN,OAAO,CAACK,QAAR,GAAmB,KAAKA,QAA1C;;AACA,YAAIC,SAAS,GAAG,CAAhB,EAAmB;AACf,gBAAM,KAAKC,MAAL,CAAYD,SAAZ,CAAN;AACA,iBAAO,KAAKR,UAAL,CAAgBC,MAAhB,EAAwBC,OAAxB,CAAP;AACH,SAHD,MAIK,IAAIM,SAAS,GAAG,CAAhB,EAAmB;AACpB,gBAAM,IAAIE,KAAJ,CAAU,uEAAV,CAAN;AACH;AACJ;;AACD,UAAIR,OAAO,CAACC,MAAZ,EAAoB;AAChBA,QAAAA,MAAM,GAAGD,OAAO,CAACC,MAAjB;AACH;AACJ;;AACD,QAAIC,MAAM,KAAK,CAAf,EAAkB;AACd,aAAO,CAAP;AACH;;AACD,UAAMO,SAAS,GAAG,MAAM,KAAKd,YAAL,CAAkBe,IAAlB,CAAuBX,MAAvB,EAA+BE,MAA/B,EAAuCC,MAAvC,CAAxB;AACA,SAAKG,QAAL,IAAiBI,SAAjB;;AACA,QAAI,CAAC,CAACT,OAAD,IAAY,CAACA,OAAO,CAACW,SAAtB,KAAoCF,SAAS,GAAGP,MAApD,EAA4D;AACxD,YAAM,IAAIb,eAAe,CAACuB,gBAApB,EAAN;AACH;;AACD,WAAOH,SAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVI,UAAU,CAACd,MAAD,EAASC,OAAT,EAAkB;AAC9B;AACA;AACA,QAAIC,MAAM,GAAG,CAAb;AACA,QAAIQ,SAAJ;AACA,QAAIP,MAAM,GAAGH,MAAM,CAACG,MAApB;;AACA,QAAIF,OAAJ,EAAa;AACT,UAAIA,OAAO,CAACC,MAAZ,EAAoB;AAChBA,QAAAA,MAAM,GAAGD,OAAO,CAACC,MAAjB;AACH;;AACD,UAAIE,MAAM,CAACC,SAAP,CAAiBJ,OAAO,CAACE,MAAzB,CAAJ,EAAsC;AAClCA,QAAAA,MAAM,GAAGF,OAAO,CAACE,MAAjB;AACH,OAFD,MAGK;AACDA,QAAAA,MAAM,IAAIF,OAAO,CAACC,MAAR,IAAkB,CAA5B;AACH;;AACD,UAAID,OAAO,CAACK,QAAZ,EAAsB;AAClB,cAAMC,SAAS,GAAGN,OAAO,CAACK,QAAR,GAAmB,KAAKA,QAA1C;;AACA,YAAIC,SAAS,GAAG,CAAhB,EAAmB;AACf,gBAAMQ,UAAU,GAAGC,MAAM,CAACC,KAAP,CAAad,MAAM,GAAGI,SAAtB,CAAnB;AACAG,UAAAA,SAAS,GAAG,MAAM,KAAKI,UAAL,CAAgBC,UAAhB,EAA4B;AAAEH,YAAAA,SAAS,EAAEX,OAAO,CAACW;AAArB,WAA5B,CAAlB;AACAG,UAAAA,UAAU,CAACG,IAAX,CAAgBlB,MAAhB,EAAwBE,MAAxB,EAAgCK,SAAhC;AACA,iBAAOG,SAAS,GAAGH,SAAnB;AACH,SALD,MAMK,IAAIA,SAAS,GAAG,CAAhB,EAAmB;AACpB,gBAAM,IAAIE,KAAJ,CAAU,gDAAV,CAAN;AACH;AACJ;AACJ;;AACD,QAAI;AACAC,MAAAA,SAAS,GAAG,MAAM,KAAKd,YAAL,CAAkBuB,IAAlB,CAAuBnB,MAAvB,EAA+BE,MAA/B,EAAuCC,MAAvC,CAAlB;AACH,KAFD,CAGA,OAAOiB,GAAP,EAAY;AACR,UAAInB,OAAO,IAAIA,OAAO,CAACW,SAAnB,IAAgCQ,GAAG,YAAY9B,eAAe,CAACuB,gBAAnE,EAAqF;AACjF,eAAO,CAAP;AACH;;AACD,YAAMO,GAAN;AACH;;AACD,QAAI,CAAC,CAACnB,OAAD,IAAY,CAACA,OAAO,CAACW,SAAtB,KAAoCF,SAAS,GAAGP,MAApD,EAA4D;AACxD,YAAM,IAAIb,eAAe,CAACuB,gBAApB,EAAN;AACH;;AACD,WAAOH,SAAP;AACH;;AACW,QAANF,MAAM,CAACL,MAAD,EAAS;AACjB;AACA,UAAMkB,OAAO,GAAGC,IAAI,CAACC,GAAL,CAAShC,aAAT,EAAwBY,MAAxB,CAAhB;AACA,UAAMqB,GAAG,GAAGR,MAAM,CAACC,KAAP,CAAaI,OAAb,CAAZ;AACA,QAAII,YAAY,GAAG,CAAnB;;AACA,WAAOA,YAAY,GAAGtB,MAAtB,EAA8B;AAC1B,YAAMuB,SAAS,GAAGvB,MAAM,GAAGsB,YAA3B;AACA,YAAMf,SAAS,GAAG,MAAM,KAAKX,UAAL,CAAgByB,GAAhB,EAAqB;AAAErB,QAAAA,MAAM,EAAEmB,IAAI,CAACC,GAAL,CAASF,OAAT,EAAkBK,SAAlB;AAAV,OAArB,CAAxB;;AACA,UAAIhB,SAAS,GAAG,CAAhB,EAAmB;AACf,eAAOA,SAAP;AACH;;AACDe,MAAAA,YAAY,IAAIf,SAAhB;AACH;;AACD,WAAOe,YAAP;AACH;;AArHmE;;AAuHxExC,OAAO,CAACE,mBAAR,GAA8BA,mBAA9B","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ReadStreamTokenizer = void 0;\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\nconst peek_readable_1 = require(\"peek-readable\");\n// import * as _debug from 'debug';\n// const debug = _debug('strtok3:ReadStreamTokenizer');\nconst maxBufferSize = 256000;\nclass ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\n    constructor(stream, fileInfo) {\n        super(fileInfo);\n        this.streamReader = new peek_readable_1.StreamReader(stream);\n    }\n    /**\n     * Get file information, an HTTP-client may implement this doing a HEAD request\n     * @return Promise with file information\n     */\n    async getFileInfo() {\n        return this.fileInfo;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param buffer - Target buffer to fill with data read from the tokenizer-stream\n     * @param options - Read behaviour options\n     * @returns Promise with number of bytes read\n     */\n    async readBuffer(buffer, options) {\n        // const _offset = position ? position : this.position;\n        // debug(`readBuffer ${_offset}...${_offset + length - 1}`);\n        let offset = 0;\n        let length = buffer.length;\n        if (options) {\n            if (Number.isInteger(options.length)) {\n                length = options.length;\n            }\n            else {\n                length -= options.offset || 0;\n            }\n            if (options.position) {\n                const skipBytes = options.position - this.position;\n                if (skipBytes > 0) {\n                    await this.ignore(skipBytes);\n                    return this.readBuffer(buffer, options);\n                }\n                else if (skipBytes < 0) {\n                    throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n                }\n            }\n            if (options.offset) {\n                offset = options.offset;\n            }\n        }\n        if (length === 0) {\n            return 0;\n        }\n        const bytesRead = await this.streamReader.read(buffer, offset, length);\n        this.position += bytesRead;\n        if ((!options || !options.mayBeLess) && bytesRead < length) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        return bytesRead;\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param buffer - Target buffer to write the data read to\n     * @param options - Read behaviour options\n     * @returns Promise with number of bytes peeked\n     */\n    async peekBuffer(buffer, options) {\n        // const _offset = position ? position : this.position;\n        // debug(`peek ${_offset}...${_offset + length - 1}`);\n        let offset = 0;\n        let bytesRead;\n        let length = buffer.length;\n        if (options) {\n            if (options.offset) {\n                offset = options.offset;\n            }\n            if (Number.isInteger(options.length)) {\n                length = options.length;\n            }\n            else {\n                length -= options.offset || 0;\n            }\n            if (options.position) {\n                const skipBytes = options.position - this.position;\n                if (skipBytes > 0) {\n                    const skipBuffer = Buffer.alloc(length + skipBytes);\n                    bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: options.mayBeLess });\n                    skipBuffer.copy(buffer, offset, skipBytes);\n                    return bytesRead - skipBytes;\n                }\n                else if (skipBytes < 0) {\n                    throw new Error('Cannot peek from a negative offset in a stream');\n                }\n            }\n        }\n        try {\n            bytesRead = await this.streamReader.peek(buffer, offset, length);\n        }\n        catch (err) {\n            if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {\n                return 0;\n            }\n            throw err;\n        }\n        if ((!options || !options.mayBeLess) && bytesRead < length) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        return bytesRead;\n    }\n    async ignore(length) {\n        // debug(`ignore ${this.position}...${this.position + length - 1}`);\n        const bufSize = Math.min(maxBufferSize, length);\n        const buf = Buffer.alloc(bufSize);\n        let totBytesRead = 0;\n        while (totBytesRead < length) {\n            const remaining = length - totBytesRead;\n            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });\n            if (bytesRead < 0) {\n                return bytesRead;\n            }\n            totBytesRead += bytesRead;\n        }\n        return totBytesRead;\n    }\n}\nexports.ReadStreamTokenizer = ReadStreamTokenizer;\n"]},"metadata":{},"sourceType":"script"}