{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.BufferTokenizer = void 0;\n\nconst peek_readable_1 = require(\"peek-readable\");\n\nclass BufferTokenizer {\n  /**\n   * Construct BufferTokenizer\n   * @param buffer - Buffer to tokenize\n   * @param fileInfo - Pass additional file information to the tokenizer\n   */\n  constructor(buffer, fileInfo) {\n    this.buffer = buffer;\n    this.position = 0;\n    this.fileInfo = fileInfo ? fileInfo : {};\n    this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : buffer.length;\n  }\n  /**\n   * Read buffer from tokenizer\n   * @param buffer\n   * @param options - Read behaviour options\n   * @returns {Promise<number>}\n   */\n\n\n  async readBuffer(buffer, options) {\n    if (options && options.position) {\n      if (options.position < this.position) {\n        throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n      }\n\n      this.position = options.position;\n    }\n\n    return this.peekBuffer(buffer, options).then(bytesRead => {\n      this.position += bytesRead;\n      return bytesRead;\n    });\n  }\n  /**\n   * Peek (read ahead) buffer from tokenizer\n   * @param buffer\n   * @param options - Read behaviour options\n   * @returns {Promise<number>}\n   */\n\n\n  async peekBuffer(buffer, options) {\n    let offset = 0;\n    let length = buffer.length;\n    let position = this.position;\n\n    if (options) {\n      if (options.position) {\n        if (options.position < this.position) {\n          throw new Error('`options.position` can be less than `tokenizer.position`');\n        }\n\n        position = options.position;\n      }\n\n      if (Number.isInteger(options.length)) {\n        length = options.length;\n      } else {\n        length -= options.offset || 0;\n      }\n\n      if (options.offset) {\n        offset = options.offset;\n      }\n    }\n\n    if (length === 0) {\n      return Promise.resolve(0);\n    }\n\n    position = position || this.position;\n\n    if (!length) {\n      length = buffer.length;\n    }\n\n    const bytes2read = Math.min(this.buffer.length - position, length);\n\n    if ((!options || !options.mayBeLess) && bytes2read < length) {\n      throw new peek_readable_1.EndOfStreamError();\n    } else {\n      this.buffer.copy(buffer, offset, position, position + bytes2read);\n      return bytes2read;\n    }\n  }\n\n  async readToken(token, position) {\n    this.position = position || this.position;\n\n    try {\n      const tv = this.peekToken(token, this.position);\n      this.position += token.len;\n      return tv;\n    } catch (err) {\n      this.position += this.buffer.length - position;\n      throw err;\n    }\n  }\n\n  async peekToken(token, position = this.position) {\n    if (this.buffer.length - position < token.len) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return token.get(this.buffer, position);\n  }\n\n  async readNumber(token) {\n    return this.readToken(token);\n  }\n\n  async peekNumber(token) {\n    return this.peekToken(token);\n  }\n  /**\n   * @return actual number of bytes ignored\n   */\n\n\n  async ignore(length) {\n    const bytesIgnored = Math.min(this.buffer.length - this.position, length);\n    this.position += bytesIgnored;\n    return bytesIgnored;\n  }\n\n  async close() {// empty\n  }\n\n}\n\nexports.BufferTokenizer = BufferTokenizer;","map":{"version":3,"sources":["/Users/johnobrien/Desktop/JOB_Developer/client/node_modules/strtok3/lib/BufferTokenizer.js"],"names":["Object","defineProperty","exports","value","BufferTokenizer","peek_readable_1","require","constructor","buffer","fileInfo","position","size","length","readBuffer","options","Error","peekBuffer","then","bytesRead","offset","Number","isInteger","Promise","resolve","bytes2read","Math","min","mayBeLess","EndOfStreamError","copy","readToken","token","tv","peekToken","len","err","get","readNumber","peekNumber","ignore","bytesIgnored","close"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,eAAR,GAA0B,KAAK,CAA/B;;AACA,MAAMC,eAAe,GAAGC,OAAO,CAAC,eAAD,CAA/B;;AACA,MAAMF,eAAN,CAAsB;AAClB;AACJ;AACA;AACA;AACA;AACIG,EAAAA,WAAW,CAACC,MAAD,EAASC,QAAT,EAAmB;AAC1B,SAAKD,MAAL,GAAcA,MAAd;AACA,SAAKE,QAAL,GAAgB,CAAhB;AACA,SAAKD,QAAL,GAAgBA,QAAQ,GAAGA,QAAH,GAAc,EAAtC;AACA,SAAKA,QAAL,CAAcE,IAAd,GAAqB,KAAKF,QAAL,CAAcE,IAAd,GAAqB,KAAKF,QAAL,CAAcE,IAAnC,GAA0CH,MAAM,CAACI,MAAtE;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVC,UAAU,CAACL,MAAD,EAASM,OAAT,EAAkB;AAC9B,QAAIA,OAAO,IAAIA,OAAO,CAACJ,QAAvB,EAAiC;AAC7B,UAAII,OAAO,CAACJ,QAAR,GAAmB,KAAKA,QAA5B,EAAsC;AAClC,cAAM,IAAIK,KAAJ,CAAU,uEAAV,CAAN;AACH;;AACD,WAAKL,QAAL,GAAgBI,OAAO,CAACJ,QAAxB;AACH;;AACD,WAAO,KAAKM,UAAL,CAAgBR,MAAhB,EAAwBM,OAAxB,EAAiCG,IAAjC,CAAsCC,SAAS,IAAI;AACtD,WAAKR,QAAL,IAAiBQ,SAAjB;AACA,aAAOA,SAAP;AACH,KAHM,CAAP;AAIH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVF,UAAU,CAACR,MAAD,EAASM,OAAT,EAAkB;AAC9B,QAAIK,MAAM,GAAG,CAAb;AACA,QAAIP,MAAM,GAAGJ,MAAM,CAACI,MAApB;AACA,QAAIF,QAAQ,GAAG,KAAKA,QAApB;;AACA,QAAII,OAAJ,EAAa;AACT,UAAIA,OAAO,CAACJ,QAAZ,EAAsB;AAClB,YAAII,OAAO,CAACJ,QAAR,GAAmB,KAAKA,QAA5B,EAAsC;AAClC,gBAAM,IAAIK,KAAJ,CAAU,0DAAV,CAAN;AACH;;AACDL,QAAAA,QAAQ,GAAGI,OAAO,CAACJ,QAAnB;AACH;;AACD,UAAIU,MAAM,CAACC,SAAP,CAAiBP,OAAO,CAACF,MAAzB,CAAJ,EAAsC;AAClCA,QAAAA,MAAM,GAAGE,OAAO,CAACF,MAAjB;AACH,OAFD,MAGK;AACDA,QAAAA,MAAM,IAAIE,OAAO,CAACK,MAAR,IAAkB,CAA5B;AACH;;AACD,UAAIL,OAAO,CAACK,MAAZ,EAAoB;AAChBA,QAAAA,MAAM,GAAGL,OAAO,CAACK,MAAjB;AACH;AACJ;;AACD,QAAIP,MAAM,KAAK,CAAf,EAAkB;AACd,aAAOU,OAAO,CAACC,OAAR,CAAgB,CAAhB,CAAP;AACH;;AACDb,IAAAA,QAAQ,GAAGA,QAAQ,IAAI,KAAKA,QAA5B;;AACA,QAAI,CAACE,MAAL,EAAa;AACTA,MAAAA,MAAM,GAAGJ,MAAM,CAACI,MAAhB;AACH;;AACD,UAAMY,UAAU,GAAGC,IAAI,CAACC,GAAL,CAAS,KAAKlB,MAAL,CAAYI,MAAZ,GAAqBF,QAA9B,EAAwCE,MAAxC,CAAnB;;AACA,QAAI,CAAC,CAACE,OAAD,IAAY,CAACA,OAAO,CAACa,SAAtB,KAAoCH,UAAU,GAAGZ,MAArD,EAA6D;AACzD,YAAM,IAAIP,eAAe,CAACuB,gBAApB,EAAN;AACH,KAFD,MAGK;AACD,WAAKpB,MAAL,CAAYqB,IAAZ,CAAiBrB,MAAjB,EAAyBW,MAAzB,EAAiCT,QAAjC,EAA2CA,QAAQ,GAAGc,UAAtD;AACA,aAAOA,UAAP;AACH;AACJ;;AACc,QAATM,SAAS,CAACC,KAAD,EAAQrB,QAAR,EAAkB;AAC7B,SAAKA,QAAL,GAAgBA,QAAQ,IAAI,KAAKA,QAAjC;;AACA,QAAI;AACA,YAAMsB,EAAE,GAAG,KAAKC,SAAL,CAAeF,KAAf,EAAsB,KAAKrB,QAA3B,CAAX;AACA,WAAKA,QAAL,IAAiBqB,KAAK,CAACG,GAAvB;AACA,aAAOF,EAAP;AACH,KAJD,CAKA,OAAOG,GAAP,EAAY;AACR,WAAKzB,QAAL,IAAiB,KAAKF,MAAL,CAAYI,MAAZ,GAAqBF,QAAtC;AACA,YAAMyB,GAAN;AACH;AACJ;;AACc,QAATF,SAAS,CAACF,KAAD,EAAQrB,QAAQ,GAAG,KAAKA,QAAxB,EAAkC;AAC7C,QAAI,KAAKF,MAAL,CAAYI,MAAZ,GAAqBF,QAArB,GAAgCqB,KAAK,CAACG,GAA1C,EAA+C;AAC3C,YAAM,IAAI7B,eAAe,CAACuB,gBAApB,EAAN;AACH;;AACD,WAAOG,KAAK,CAACK,GAAN,CAAU,KAAK5B,MAAf,EAAuBE,QAAvB,CAAP;AACH;;AACe,QAAV2B,UAAU,CAACN,KAAD,EAAQ;AACpB,WAAO,KAAKD,SAAL,CAAeC,KAAf,CAAP;AACH;;AACe,QAAVO,UAAU,CAACP,KAAD,EAAQ;AACpB,WAAO,KAAKE,SAAL,CAAeF,KAAf,CAAP;AACH;AACD;AACJ;AACA;;;AACgB,QAANQ,MAAM,CAAC3B,MAAD,EAAS;AACjB,UAAM4B,YAAY,GAAGf,IAAI,CAACC,GAAL,CAAS,KAAKlB,MAAL,CAAYI,MAAZ,GAAqB,KAAKF,QAAnC,EAA6CE,MAA7C,CAArB;AACA,SAAKF,QAAL,IAAiB8B,YAAjB;AACA,WAAOA,YAAP;AACH;;AACU,QAALC,KAAK,GAAG,CACV;AACH;;AA3GiB;;AA6GtBvC,OAAO,CAACE,eAAR,GAA0BA,eAA1B","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.BufferTokenizer = void 0;\nconst peek_readable_1 = require(\"peek-readable\");\nclass BufferTokenizer {\n    /**\n     * Construct BufferTokenizer\n     * @param buffer - Buffer to tokenize\n     * @param fileInfo - Pass additional file information to the tokenizer\n     */\n    constructor(buffer, fileInfo) {\n        this.buffer = buffer;\n        this.position = 0;\n        this.fileInfo = fileInfo ? fileInfo : {};\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : buffer.length;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async readBuffer(buffer, options) {\n        if (options && options.position) {\n            if (options.position < this.position) {\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n            }\n            this.position = options.position;\n        }\n        return this.peekBuffer(buffer, options).then(bytesRead => {\n            this.position += bytesRead;\n            return bytesRead;\n        });\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async peekBuffer(buffer, options) {\n        let offset = 0;\n        let length = buffer.length;\n        let position = this.position;\n        if (options) {\n            if (options.position) {\n                if (options.position < this.position) {\n                    throw new Error('`options.position` can be less than `tokenizer.position`');\n                }\n                position = options.position;\n            }\n            if (Number.isInteger(options.length)) {\n                length = options.length;\n            }\n            else {\n                length -= options.offset || 0;\n            }\n            if (options.offset) {\n                offset = options.offset;\n            }\n        }\n        if (length === 0) {\n            return Promise.resolve(0);\n        }\n        position = position || this.position;\n        if (!length) {\n            length = buffer.length;\n        }\n        const bytes2read = Math.min(this.buffer.length - position, length);\n        if ((!options || !options.mayBeLess) && bytes2read < length) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        else {\n            this.buffer.copy(buffer, offset, position, position + bytes2read);\n            return bytes2read;\n        }\n    }\n    async readToken(token, position) {\n        this.position = position || this.position;\n        try {\n            const tv = this.peekToken(token, this.position);\n            this.position += token.len;\n            return tv;\n        }\n        catch (err) {\n            this.position += this.buffer.length - position;\n            throw err;\n        }\n    }\n    async peekToken(token, position = this.position) {\n        if (this.buffer.length - position < token.len) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        return token.get(this.buffer, position);\n    }\n    async readNumber(token) {\n        return this.readToken(token);\n    }\n    async peekNumber(token) {\n        return this.peekToken(token);\n    }\n    /**\n     * @return actual number of bytes ignored\n     */\n    async ignore(length) {\n        const bytesIgnored = Math.min(this.buffer.length - this.position, length);\n        this.position += bytesIgnored;\n        return bytesIgnored;\n    }\n    async close() {\n        // empty\n    }\n}\nexports.BufferTokenizer = BufferTokenizer;\n"]},"metadata":{},"sourceType":"script"}