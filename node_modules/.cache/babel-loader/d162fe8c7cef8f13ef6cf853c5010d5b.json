{"ast":null,"code":"\"use strict\";\n\nvar _regeneratorRuntime = require(\"/Users/johnobrien/Desktop/Rumblr_PROD/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/Users/johnobrien/Desktop/Rumblr_PROD/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/Users/johnobrien/Desktop/Rumblr_PROD/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/johnobrien/Desktop/Rumblr_PROD/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.BufferTokenizer = void 0;\n\nvar peek_readable_1 = require(\"peek-readable\");\n\nvar BufferTokenizer = /*#__PURE__*/function () {\n  /**\n   * Construct BufferTokenizer\n   * @param buffer - Buffer to tokenize\n   * @param fileInfo - Pass additional file information to the tokenizer\n   */\n  function BufferTokenizer(buffer, fileInfo) {\n    _classCallCheck(this, BufferTokenizer);\n\n    this.buffer = buffer;\n    this.position = 0;\n    this.fileInfo = fileInfo ? fileInfo : {};\n    this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : buffer.length;\n  }\n  /**\n   * Read buffer from tokenizer\n   * @param buffer\n   * @param options - Read behaviour options\n   * @returns {Promise<number>}\n   */\n\n\n  _createClass(BufferTokenizer, [{\n    key: \"readBuffer\",\n    value: function () {\n      var _readBuffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(buffer, options) {\n        var _this = this;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!(options && options.position)) {\n                  _context.next = 4;\n                  break;\n                }\n\n                if (!(options.position < this.position)) {\n                  _context.next = 3;\n                  break;\n                }\n\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n\n              case 3:\n                this.position = options.position;\n\n              case 4:\n                return _context.abrupt(\"return\", this.peekBuffer(buffer, options).then(function (bytesRead) {\n                  _this.position += bytesRead;\n                  return bytesRead;\n                }));\n\n              case 5:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function readBuffer(_x, _x2) {\n        return _readBuffer.apply(this, arguments);\n      }\n\n      return readBuffer;\n    }()\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n\n  }, {\n    key: \"peekBuffer\",\n    value: function () {\n      var _peekBuffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(buffer, options) {\n        var offset, length, position, bytes2read;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                offset = 0;\n                length = buffer.length;\n                position = this.position;\n\n                if (!options) {\n                  _context2.next = 10;\n                  break;\n                }\n\n                if (!options.position) {\n                  _context2.next = 8;\n                  break;\n                }\n\n                if (!(options.position < this.position)) {\n                  _context2.next = 7;\n                  break;\n                }\n\n                throw new Error('`options.position` can be less than `tokenizer.position`');\n\n              case 7:\n                position = options.position;\n\n              case 8:\n                if (Number.isInteger(options.length)) {\n                  length = options.length;\n                } else {\n                  length -= options.offset || 0;\n                }\n\n                if (options.offset) {\n                  offset = options.offset;\n                }\n\n              case 10:\n                if (!(length === 0)) {\n                  _context2.next = 12;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\", Promise.resolve(0));\n\n              case 12:\n                position = position || this.position;\n\n                if (!length) {\n                  length = buffer.length;\n                }\n\n                bytes2read = Math.min(this.buffer.length - position, length);\n\n                if (!((!options || !options.mayBeLess) && bytes2read < length)) {\n                  _context2.next = 19;\n                  break;\n                }\n\n                throw new peek_readable_1.EndOfStreamError();\n\n              case 19:\n                this.buffer.copy(buffer, offset, position, position + bytes2read);\n                return _context2.abrupt(\"return\", bytes2read);\n\n              case 21:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function peekBuffer(_x3, _x4) {\n        return _peekBuffer.apply(this, arguments);\n      }\n\n      return peekBuffer;\n    }()\n  }, {\n    key: \"readToken\",\n    value: function () {\n      var _readToken = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(token, position) {\n        var tv;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                this.position = position || this.position;\n                _context3.prev = 1;\n                tv = this.peekToken(token, this.position);\n                this.position += token.len;\n                return _context3.abrupt(\"return\", tv);\n\n              case 7:\n                _context3.prev = 7;\n                _context3.t0 = _context3[\"catch\"](1);\n                this.position += this.buffer.length - position;\n                throw _context3.t0;\n\n              case 11:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this, [[1, 7]]);\n      }));\n\n      function readToken(_x5, _x6) {\n        return _readToken.apply(this, arguments);\n      }\n\n      return readToken;\n    }()\n  }, {\n    key: \"peekToken\",\n    value: function () {\n      var _peekToken = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(token) {\n        var position,\n            _args4 = arguments;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                position = _args4.length > 1 && _args4[1] !== undefined ? _args4[1] : this.position;\n\n                if (!(this.buffer.length - position < token.len)) {\n                  _context4.next = 3;\n                  break;\n                }\n\n                throw new peek_readable_1.EndOfStreamError();\n\n              case 3:\n                return _context4.abrupt(\"return\", token.get(this.buffer, position));\n\n              case 4:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function peekToken(_x7) {\n        return _peekToken.apply(this, arguments);\n      }\n\n      return peekToken;\n    }()\n  }, {\n    key: \"readNumber\",\n    value: function () {\n      var _readNumber = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(token) {\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                return _context5.abrupt(\"return\", this.readToken(token));\n\n              case 1:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5, this);\n      }));\n\n      function readNumber(_x8) {\n        return _readNumber.apply(this, arguments);\n      }\n\n      return readNumber;\n    }()\n  }, {\n    key: \"peekNumber\",\n    value: function () {\n      var _peekNumber = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee6(token) {\n        return _regeneratorRuntime.wrap(function _callee6$(_context6) {\n          while (1) {\n            switch (_context6.prev = _context6.next) {\n              case 0:\n                return _context6.abrupt(\"return\", this.peekToken(token));\n\n              case 1:\n              case \"end\":\n                return _context6.stop();\n            }\n          }\n        }, _callee6, this);\n      }));\n\n      function peekNumber(_x9) {\n        return _peekNumber.apply(this, arguments);\n      }\n\n      return peekNumber;\n    }()\n    /**\n     * @return actual number of bytes ignored\n     */\n\n  }, {\n    key: \"ignore\",\n    value: function () {\n      var _ignore = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee7(length) {\n        var bytesIgnored;\n        return _regeneratorRuntime.wrap(function _callee7$(_context7) {\n          while (1) {\n            switch (_context7.prev = _context7.next) {\n              case 0:\n                bytesIgnored = Math.min(this.buffer.length - this.position, length);\n                this.position += bytesIgnored;\n                return _context7.abrupt(\"return\", bytesIgnored);\n\n              case 3:\n              case \"end\":\n                return _context7.stop();\n            }\n          }\n        }, _callee7, this);\n      }));\n\n      function ignore(_x10) {\n        return _ignore.apply(this, arguments);\n      }\n\n      return ignore;\n    }()\n  }, {\n    key: \"close\",\n    value: function () {\n      var _close = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee8() {\n        return _regeneratorRuntime.wrap(function _callee8$(_context8) {\n          while (1) {\n            switch (_context8.prev = _context8.next) {\n              case 0:\n              case \"end\":\n                return _context8.stop();\n            }\n          }\n        }, _callee8);\n      }));\n\n      function close() {\n        return _close.apply(this, arguments);\n      }\n\n      return close;\n    }()\n  }]);\n\n  return BufferTokenizer;\n}();\n\nexports.BufferTokenizer = BufferTokenizer;","map":{"version":3,"sources":["/Users/johnobrien/Desktop/Rumblr_PROD/client/node_modules/strtok3/lib/BufferTokenizer.js"],"names":["Object","defineProperty","exports","value","BufferTokenizer","peek_readable_1","require","buffer","fileInfo","position","size","length","options","Error","peekBuffer","then","bytesRead","offset","Number","isInteger","Promise","resolve","bytes2read","Math","min","mayBeLess","EndOfStreamError","copy","token","tv","peekToken","len","get","readToken","bytesIgnored"],"mappings":"AAAA;;;;;;;;;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,eAAR,GAA0B,KAAK,CAA/B;;AACA,IAAMC,eAAe,GAAGC,OAAO,CAAC,eAAD,CAA/B;;IACMF,e;AACF;AACJ;AACA;AACA;AACA;AACI,2BAAYG,MAAZ,EAAoBC,QAApB,EAA8B;AAAA;;AAC1B,SAAKD,MAAL,GAAcA,MAAd;AACA,SAAKE,QAAL,GAAgB,CAAhB;AACA,SAAKD,QAAL,GAAgBA,QAAQ,GAAGA,QAAH,GAAc,EAAtC;AACA,SAAKA,QAAL,CAAcE,IAAd,GAAqB,KAAKF,QAAL,CAAcE,IAAd,GAAqB,KAAKF,QAAL,CAAcE,IAAnC,GAA0CH,MAAM,CAACI,MAAtE;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;;;;iFACI,iBAAiBJ,MAAjB,EAAyBK,OAAzB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,sBACQA,OAAO,IAAIA,OAAO,CAACH,QAD3B;AAAA;AAAA;AAAA;;AAAA,sBAEYG,OAAO,CAACH,QAAR,GAAmB,KAAKA,QAFpC;AAAA;AAAA;AAAA;;AAAA,sBAGkB,IAAII,KAAJ,CAAU,uEAAV,CAHlB;;AAAA;AAKQ,qBAAKJ,QAAL,GAAgBG,OAAO,CAACH,QAAxB;;AALR;AAAA,iDAOW,KAAKK,UAAL,CAAgBP,MAAhB,EAAwBK,OAAxB,EAAiCG,IAAjC,CAAsC,UAAAC,SAAS,EAAI;AACtD,kBAAA,KAAI,CAACP,QAAL,IAAiBO,SAAjB;AACA,yBAAOA,SAAP;AACH,iBAHM,CAPX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AAYA;AACJ;AACA;AACA;AACA;AACA;;;;;iFACI,kBAAiBT,MAAjB,EAAyBK,OAAzB;AAAA;AAAA;AAAA;AAAA;AAAA;AACQK,gBAAAA,MADR,GACiB,CADjB;AAEQN,gBAAAA,MAFR,GAEiBJ,MAAM,CAACI,MAFxB;AAGQF,gBAAAA,QAHR,GAGmB,KAAKA,QAHxB;;AAAA,qBAIQG,OAJR;AAAA;AAAA;AAAA;;AAAA,qBAKYA,OAAO,CAACH,QALpB;AAAA;AAAA;AAAA;;AAAA,sBAMgBG,OAAO,CAACH,QAAR,GAAmB,KAAKA,QANxC;AAAA;AAAA;AAAA;;AAAA,sBAOsB,IAAII,KAAJ,CAAU,0DAAV,CAPtB;;AAAA;AASYJ,gBAAAA,QAAQ,GAAGG,OAAO,CAACH,QAAnB;;AATZ;AAWQ,oBAAIS,MAAM,CAACC,SAAP,CAAiBP,OAAO,CAACD,MAAzB,CAAJ,EAAsC;AAClCA,kBAAAA,MAAM,GAAGC,OAAO,CAACD,MAAjB;AACH,iBAFD,MAGK;AACDA,kBAAAA,MAAM,IAAIC,OAAO,CAACK,MAAR,IAAkB,CAA5B;AACH;;AACD,oBAAIL,OAAO,CAACK,MAAZ,EAAoB;AAChBA,kBAAAA,MAAM,GAAGL,OAAO,CAACK,MAAjB;AACH;;AAnBT;AAAA,sBAqBQN,MAAM,KAAK,CArBnB;AAAA;AAAA;AAAA;;AAAA,kDAsBeS,OAAO,CAACC,OAAR,CAAgB,CAAhB,CAtBf;;AAAA;AAwBIZ,gBAAAA,QAAQ,GAAGA,QAAQ,IAAI,KAAKA,QAA5B;;AACA,oBAAI,CAACE,MAAL,EAAa;AACTA,kBAAAA,MAAM,GAAGJ,MAAM,CAACI,MAAhB;AACH;;AACKW,gBAAAA,UA5BV,GA4BuBC,IAAI,CAACC,GAAL,CAAS,KAAKjB,MAAL,CAAYI,MAAZ,GAAqBF,QAA9B,EAAwCE,MAAxC,CA5BvB;;AAAA,sBA6BQ,CAAC,CAACC,OAAD,IAAY,CAACA,OAAO,CAACa,SAAtB,KAAoCH,UAAU,GAAGX,MA7BzD;AAAA;AAAA;AAAA;;AAAA,sBA8Bc,IAAIN,eAAe,CAACqB,gBAApB,EA9Bd;;AAAA;AAiCQ,qBAAKnB,MAAL,CAAYoB,IAAZ,CAAiBpB,MAAjB,EAAyBU,MAAzB,EAAiCR,QAAjC,EAA2CA,QAAQ,GAAGa,UAAtD;AAjCR,kDAkCeA,UAlCf;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;gFAqCA,kBAAgBM,KAAhB,EAAuBnB,QAAvB;AAAA;AAAA;AAAA;AAAA;AAAA;AACI,qBAAKA,QAAL,GAAgBA,QAAQ,IAAI,KAAKA,QAAjC;AADJ;AAGcoB,gBAAAA,EAHd,GAGmB,KAAKC,SAAL,CAAeF,KAAf,EAAsB,KAAKnB,QAA3B,CAHnB;AAIQ,qBAAKA,QAAL,IAAiBmB,KAAK,CAACG,GAAvB;AAJR,kDAKeF,EALf;;AAAA;AAAA;AAAA;AAQQ,qBAAKpB,QAAL,IAAiB,KAAKF,MAAL,CAAYI,MAAZ,GAAqBF,QAAtC;AARR;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;gFAYA,kBAAgBmB,KAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuBnB,gBAAAA,QAAvB,8DAAkC,KAAKA,QAAvC;;AAAA,sBACQ,KAAKF,MAAL,CAAYI,MAAZ,GAAqBF,QAArB,GAAgCmB,KAAK,CAACG,GAD9C;AAAA;AAAA;AAAA;;AAAA,sBAEc,IAAI1B,eAAe,CAACqB,gBAApB,EAFd;;AAAA;AAAA,kDAIWE,KAAK,CAACI,GAAN,CAAU,KAAKzB,MAAf,EAAuBE,QAAvB,CAJX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;iFAMA,kBAAiBmB,KAAjB;AAAA;AAAA;AAAA;AAAA;AAAA,kDACW,KAAKK,SAAL,CAAeL,KAAf,CADX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;iFAGA,kBAAiBA,KAAjB;AAAA;AAAA;AAAA;AAAA;AAAA,kDACW,KAAKE,SAAL,CAAeF,KAAf,CADX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AAGA;AACJ;AACA;;;;;6EACI,kBAAajB,MAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AACUuB,gBAAAA,YADV,GACyBX,IAAI,CAACC,GAAL,CAAS,KAAKjB,MAAL,CAAYI,MAAZ,GAAqB,KAAKF,QAAnC,EAA6CE,MAA7C,CADzB;AAEI,qBAAKF,QAAL,IAAiByB,YAAjB;AAFJ,kDAGWA,YAHX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;4EAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;;;AAIJhC,OAAO,CAACE,eAAR,GAA0BA,eAA1B","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.BufferTokenizer = void 0;\nconst peek_readable_1 = require(\"peek-readable\");\nclass BufferTokenizer {\n    /**\n     * Construct BufferTokenizer\n     * @param buffer - Buffer to tokenize\n     * @param fileInfo - Pass additional file information to the tokenizer\n     */\n    constructor(buffer, fileInfo) {\n        this.buffer = buffer;\n        this.position = 0;\n        this.fileInfo = fileInfo ? fileInfo : {};\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : buffer.length;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async readBuffer(buffer, options) {\n        if (options && options.position) {\n            if (options.position < this.position) {\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n            }\n            this.position = options.position;\n        }\n        return this.peekBuffer(buffer, options).then(bytesRead => {\n            this.position += bytesRead;\n            return bytesRead;\n        });\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async peekBuffer(buffer, options) {\n        let offset = 0;\n        let length = buffer.length;\n        let position = this.position;\n        if (options) {\n            if (options.position) {\n                if (options.position < this.position) {\n                    throw new Error('`options.position` can be less than `tokenizer.position`');\n                }\n                position = options.position;\n            }\n            if (Number.isInteger(options.length)) {\n                length = options.length;\n            }\n            else {\n                length -= options.offset || 0;\n            }\n            if (options.offset) {\n                offset = options.offset;\n            }\n        }\n        if (length === 0) {\n            return Promise.resolve(0);\n        }\n        position = position || this.position;\n        if (!length) {\n            length = buffer.length;\n        }\n        const bytes2read = Math.min(this.buffer.length - position, length);\n        if ((!options || !options.mayBeLess) && bytes2read < length) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        else {\n            this.buffer.copy(buffer, offset, position, position + bytes2read);\n            return bytes2read;\n        }\n    }\n    async readToken(token, position) {\n        this.position = position || this.position;\n        try {\n            const tv = this.peekToken(token, this.position);\n            this.position += token.len;\n            return tv;\n        }\n        catch (err) {\n            this.position += this.buffer.length - position;\n            throw err;\n        }\n    }\n    async peekToken(token, position = this.position) {\n        if (this.buffer.length - position < token.len) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        return token.get(this.buffer, position);\n    }\n    async readNumber(token) {\n        return this.readToken(token);\n    }\n    async peekNumber(token) {\n        return this.peekToken(token);\n    }\n    /**\n     * @return actual number of bytes ignored\n     */\n    async ignore(length) {\n        const bytesIgnored = Math.min(this.buffer.length - this.position, length);\n        this.position += bytesIgnored;\n        return bytesIgnored;\n    }\n    async close() {\n        // empty\n    }\n}\nexports.BufferTokenizer = BufferTokenizer;\n"]},"metadata":{},"sourceType":"script"}