{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.AbstractTokenizer = void 0;\n\nconst peek_readable_1 = require(\"peek-readable\");\n/**\n * Core tokenizer\n */\n\n\nclass AbstractTokenizer {\n  constructor(fileInfo) {\n    /**\n     * Tokenizer-stream position\n     */\n    this.position = 0;\n    this.numBuffer = Buffer.alloc(10);\n    this.fileInfo = fileInfo ? fileInfo : {};\n  }\n  /**\n   * Read a token from the tokenizer-stream\n   * @param token - The token to read\n   * @param position - If provided, the desired position in the tokenizer-stream\n   * @returns Promise with token data\n   */\n\n\n  async readToken(token, position) {\n    const buffer = Buffer.alloc(token.len);\n    const len = await this.readBuffer(buffer, {\n      position\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(buffer, 0);\n  }\n  /**\n   * Peek a token from the tokenizer-stream.\n   * @param token - Token to peek from the tokenizer-stream.\n   * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\n   * @returns Promise with token data\n   */\n\n\n  async peekToken(token, position = this.position) {\n    const buffer = Buffer.alloc(token.len);\n    const len = await this.peekBuffer(buffer, {\n      position\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(buffer, 0);\n  }\n  /**\n   * Read a numeric token from the stream\n   * @param token - Numeric token\n   * @returns Promise with number\n   */\n\n\n  async readNumber(token) {\n    const len = await this.readBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\n   * Read a numeric token from the stream\n   * @param token - Numeric token\n   * @returns Promise with number\n   */\n\n\n  async peekNumber(token) {\n    const len = await this.peekBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new peek_readable_1.EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n\n  async close() {// empty\n  }\n\n}\n\nexports.AbstractTokenizer = AbstractTokenizer;","map":{"version":3,"sources":["/Users/johnobrien/Desktop/JOB_Developer/client/node_modules/strtok3/lib/AbstractTokenizer.js"],"names":["Object","defineProperty","exports","value","AbstractTokenizer","peek_readable_1","require","constructor","fileInfo","position","numBuffer","Buffer","alloc","readToken","token","buffer","len","readBuffer","EndOfStreamError","get","peekToken","peekBuffer","readNumber","length","peekNumber","close"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,iBAAR,GAA4B,KAAK,CAAjC;;AACA,MAAMC,eAAe,GAAGC,OAAO,CAAC,eAAD,CAA/B;AACA;AACA;AACA;;;AACA,MAAMF,iBAAN,CAAwB;AACpBG,EAAAA,WAAW,CAACC,QAAD,EAAW;AAClB;AACR;AACA;AACQ,SAAKC,QAAL,GAAgB,CAAhB;AACA,SAAKC,SAAL,GAAiBC,MAAM,CAACC,KAAP,CAAa,EAAb,CAAjB;AACA,SAAKJ,QAAL,GAAgBA,QAAQ,GAAGA,QAAH,GAAc,EAAtC;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACmB,QAATK,SAAS,CAACC,KAAD,EAAQL,QAAR,EAAkB;AAC7B,UAAMM,MAAM,GAAGJ,MAAM,CAACC,KAAP,CAAaE,KAAK,CAACE,GAAnB,CAAf;AACA,UAAMA,GAAG,GAAG,MAAM,KAAKC,UAAL,CAAgBF,MAAhB,EAAwB;AAAEN,MAAAA;AAAF,KAAxB,CAAlB;AACA,QAAIO,GAAG,GAAGF,KAAK,CAACE,GAAhB,EACI,MAAM,IAAIX,eAAe,CAACa,gBAApB,EAAN;AACJ,WAAOJ,KAAK,CAACK,GAAN,CAAUJ,MAAV,EAAkB,CAAlB,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACmB,QAATK,SAAS,CAACN,KAAD,EAAQL,QAAQ,GAAG,KAAKA,QAAxB,EAAkC;AAC7C,UAAMM,MAAM,GAAGJ,MAAM,CAACC,KAAP,CAAaE,KAAK,CAACE,GAAnB,CAAf;AACA,UAAMA,GAAG,GAAG,MAAM,KAAKK,UAAL,CAAgBN,MAAhB,EAAwB;AAAEN,MAAAA;AAAF,KAAxB,CAAlB;AACA,QAAIO,GAAG,GAAGF,KAAK,CAACE,GAAhB,EACI,MAAM,IAAIX,eAAe,CAACa,gBAApB,EAAN;AACJ,WAAOJ,KAAK,CAACK,GAAN,CAAUJ,MAAV,EAAkB,CAAlB,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACoB,QAAVO,UAAU,CAACR,KAAD,EAAQ;AACpB,UAAME,GAAG,GAAG,MAAM,KAAKC,UAAL,CAAgB,KAAKP,SAArB,EAAgC;AAAEa,MAAAA,MAAM,EAAET,KAAK,CAACE;AAAhB,KAAhC,CAAlB;AACA,QAAIA,GAAG,GAAGF,KAAK,CAACE,GAAhB,EACI,MAAM,IAAIX,eAAe,CAACa,gBAApB,EAAN;AACJ,WAAOJ,KAAK,CAACK,GAAN,CAAU,KAAKT,SAAf,EAA0B,CAA1B,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACoB,QAAVc,UAAU,CAACV,KAAD,EAAQ;AACpB,UAAME,GAAG,GAAG,MAAM,KAAKK,UAAL,CAAgB,KAAKX,SAArB,EAAgC;AAAEa,MAAAA,MAAM,EAAET,KAAK,CAACE;AAAhB,KAAhC,CAAlB;AACA,QAAIA,GAAG,GAAGF,KAAK,CAACE,GAAhB,EACI,MAAM,IAAIX,eAAe,CAACa,gBAApB,EAAN;AACJ,WAAOJ,KAAK,CAACK,GAAN,CAAU,KAAKT,SAAf,EAA0B,CAA1B,CAAP;AACH;;AACU,QAALe,KAAK,GAAG,CACV;AACH;;AA3DmB;;AA6DxBvB,OAAO,CAACE,iBAAR,GAA4BA,iBAA5B","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AbstractTokenizer = void 0;\nconst peek_readable_1 = require(\"peek-readable\");\n/**\n * Core tokenizer\n */\nclass AbstractTokenizer {\n    constructor(fileInfo) {\n        /**\n         * Tokenizer-stream position\n         */\n        this.position = 0;\n        this.numBuffer = Buffer.alloc(10);\n        this.fileInfo = fileInfo ? fileInfo : {};\n    }\n    /**\n     * Read a token from the tokenizer-stream\n     * @param token - The token to read\n     * @param position - If provided, the desired position in the tokenizer-stream\n     * @returns Promise with token data\n     */\n    async readToken(token, position) {\n        const buffer = Buffer.alloc(token.len);\n        const len = await this.readBuffer(buffer, { position });\n        if (len < token.len)\n            throw new peek_readable_1.EndOfStreamError();\n        return token.get(buffer, 0);\n    }\n    /**\n     * Peek a token from the tokenizer-stream.\n     * @param token - Token to peek from the tokenizer-stream.\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\n     * @returns Promise with token data\n     */\n    async peekToken(token, position = this.position) {\n        const buffer = Buffer.alloc(token.len);\n        const len = await this.peekBuffer(buffer, { position });\n        if (len < token.len)\n            throw new peek_readable_1.EndOfStreamError();\n        return token.get(buffer, 0);\n    }\n    /**\n     * Read a numeric token from the stream\n     * @param token - Numeric token\n     * @returns Promise with number\n     */\n    async readNumber(token) {\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\n        if (len < token.len)\n            throw new peek_readable_1.EndOfStreamError();\n        return token.get(this.numBuffer, 0);\n    }\n    /**\n     * Read a numeric token from the stream\n     * @param token - Numeric token\n     * @returns Promise with number\n     */\n    async peekNumber(token) {\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\n        if (len < token.len)\n            throw new peek_readable_1.EndOfStreamError();\n        return token.get(this.numBuffer, 0);\n    }\n    async close() {\n        // empty\n    }\n}\nexports.AbstractTokenizer = AbstractTokenizer;\n"]},"metadata":{},"sourceType":"script"}